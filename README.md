# Naive RAG Challenge - BeyondLLM Framework

This repository contains the **RAG (Retrieval-Augmented Generation)** challenge conducted by BeyondLLM. In this challenge, I created a naive RAG using the BeyondLLM framework with just 5-7 lines of code and deployed the solution on **Streamlit Cloud**.

## Features

- Built using the BeyondLLM framework for efficient retrieval and generation tasks.
- Deployed on **Streamlit Cloud** for easy interaction.
- Supports multiple LLMs including OpenAI, Claude, Llama 3.1, and Gemini.

## Installation

To set up and run this project, follow these steps:

### 1. Clone the Repository

```bash
git clone https://github.com/your-repo-url.git
cd your-repo-directory
```
### 2.Create a virtual environment:

```bash
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```
### 3.Run the application:

```bash
streamlit run app.py
```

### Configuration
Configure your API keys to interact with different LLMs (OpenAI, Claude, Llama 3.1, Gemini). You can set them in your environment variables or a config file.
